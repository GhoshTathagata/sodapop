#!/usr/bin/env python

'INFER-POP-PARAMS -- infer population parameters based on population model and observations'
__usage__ = 'infer-pop-params pop_params.csv samples.csv [-p pop_model -o /path/to/output.csv -v]'
__author__ = 'Philippe Landry (pgjlandry@gmail.com)'
__date__ = '01-2021'

from argparse import ArgumentParser
import numpy as np
import numpy.random
from time import time
import os
import emcee
import sodapop.populations as pop

parser = ArgumentParser(description=__doc__)
parser.add_argument('popparams')
parser.add_argument('likedata', nargs='+')
parser.add_argument('-d', '--delim', help='delimiter for data file, DEFAULT=","', default=',')
parser.add_argument('-c', '--cols', help='name of mass1, mass2 and likelihood data columns to use, DEFAULT="m1 m2 likelihood"', default=['m1','m2','likelihood'], nargs='+')
parser.add_argument('-p', '--popmodel', help='name of population model, DEFAULT="doublegaussian_m1m2"', default="doublegaussian_m1m2", nargs='+')
parser.add_argument('-s', '--select', help='name of selection function, DEFAULT=False', default=False)
parser.add_argument('-o', '--outpath', help='path for output population parameter samples, DEFAULT=AUTO', default=False)
parser.add_argument('-m', '--maxsamps', help='maximum number of likelihood samples to use, DEFAULT=5e3', default=5e3)
parser.add_argument('-S', '--selectsamps', help='number of samples to use for integrating selection function, DEFAULT=5e3', default=5e3)
parser.add_argument('-P', '--postsamps', help='target number of posterior samples, DEFAULT=1e4', default=1e4)
parser.add_argument('-w', '--numwalkers', help='number of MCMC chains, DEFAULT=1e2', default=1e2)
parser.add_argument('-b', '--numburnin', help='number of burn-in samples, DEFAULT=5e2', default=5e2)
parser.add_argument('-v', '--verbose', action='store_true', default=False)
args = parser.parse_args()

if args.outpath: out_path = args.outpath
else: out_path = os.path.dirname(args.likedata[0])+'/'+args.popmodel[0]+'.csv'

N_WALKERS = int(args.numwalkers)
N_BURNIN = int(args.numburnin)
N_POSTS = int(args.postsamps)
N_SELECT = int(args.selectsamps)
N_LIKES = int(args.maxsamps)
PRIOR_M_LOWER = 3.
PRIOR_M_UPPER = 23.
DL_LOWER = 1.
DL_UPPER = 1000.

num_masses = len(args.cols)-1

if args.verbose: print('walkers: {0}, burn in: {1}, target posterior samples: {2}, likelihood samples: {3}, selection effect samples: {4}'.format(N_WALKERS,N_BURNIN,N_POSTS,N_LIKES,N_SELECT))

# get population model

if len(args.popmodel) == 1: pop_probs = [pop.get_pop_prior(args.popmodel[0]) for likedata in args.likedata]
else: pop_probs = [pop.get_pop_prior(args.popmodel[i]) for i,likedata in enumerate(args.likedata)]

if args.select: select_func = pop.get_select_func(args.select)
else: select_func = lambda *x : 1.

# load likelihood samples

if args.verbose: print('Loading likelihood data...')

likesamps = []
for likedata in args.likedata:

	data = np.genfromtxt(likedata,names=True,dtype=None,delimiter=args.delim)
	cols = data.dtype.names
	if args.verbose: print(cols) # check column names; use source-frame masses
	
	wts = data[args.cols[-1]]

	if num_masses == 2:
		m1s = data[args.cols[0]] # COLUMN NAMES FOR INPUT
		m2s = data[args.cols[1]]
		ids = np.random.choice(range(len(m1s)),N_LIKES,replace=True,p=wts/np.sum(wts))
		samps = np.array([(m1s[i],m2s[i]) for i in ids],dtype='f,f')

	else:	
		ms = data[args.cols[0]]
		samps = np.random.choice(ms,N_LIKES,replace=True,p=wts/np.sum(wts))
	
	likesamps.append(samps)

# load same number of uniform samples

def samples_for_select(pop_model,lambdaa,mmin_bh=PRIOR_M_LOWER,mmax_bh=PRIOR_M_UPPER):

	if num_masses > 1.: 
		if pop_model == 'unif_m1m2' or pop_model == 'peakcut_m1m2' or pop_model == 'bimodcut_m1m2':

			mIsu = np.random.uniform(lambdaa[-2],lambdaa[-1],N_SELECT)
			mIIsu = np.random.uniform(lambdaa[-2],lambdaa[-1],N_SELECT)
			dlsu = np.random.uniform(DL_LOWER,DL_UPPER,N_SELECT)
			m1su = [max(mI,mII) for mI,mII in zip(mIsu,mIIsu)]
			m2su = [min(mI,mII) for mI,mII in zip(mIsu,mIIsu)]
			uniform_samples = list(zip(m1su,m2su,dlsu))	
		
		elif pop_model == 'unif_m1_unif_m2' or pop_model == 'unif_m1_peakcut_m2' or pop_model == 'unif_m1_bimodcut_m2':
	
			m1su = np.random.uniform(mmin_bh,mmax_bh,N_SELECT)
			m2su = np.random.uniform(lambdaa[-2],lambdaa[-1],N_SELECT)
			dlsu = np.random.uniform(DL_LOWER,DL_UPPER,N_SELECT)
			uniform_samples = list(zip(m1su,m2su,dlsu))	
		
	else:
		mIsu = np.random.uniform(lambdaa[-2],lambdaa[-1],N_SELECT)
		dlsu = np.random.uniform(DL_LOWER,DL_UPPER,N_SELECT)
		uniform_samples = list(zip(mIsu,dlsu))

	return uniform_samples
		
# calculate population parameter posterior

pop_params = np.genfromtxt(args.popparams, names=True, dtype=None, delimiter=args.delim, encoding=None)
pop_param_names = pop_params.dtype.names

def logprior(lambdaa, pop_params, pop_model):

	norm = np.prod([max(pop_params[param])-min(pop_params[param]) for param in pop_params.dtype.names])
	
	mmin = lambdaa[-2]
	mmax = lambdaa[-1]
	
	if pop_model == 'unif_m1m2':

		prior = 1./norm if min(pop_params['mmin']) <= mmin <= max(pop_params['mmin']) and min(pop_params['mmax']) <= mmax <= max(pop_params['mmax']) and mmin < mmax else 0.
		
	elif pop_model == 'peakcut_m1m2':
	
		mu = lambdaa[0]
		sigma = lambdaa[1]
	
		prior = 1./norm if min(pop_params['mmin']) <= mmin <= max(pop_params['mmin']) and min(pop_params['mmax']) <= mmax <= max(pop_params['mmax']) and mmin < mmax and max(mmin,min(pop_params['mu'])) <= mu <= min(mmax,max(pop_params['mu'])) and min(pop_params['sigma']) <= sigma <= max(pop_params['sigma']) else 0.
		
	elif pop_model == 'bimodcut_m1m2':
	
		mu1 = lambdaa[0]
		sigma1 = lambdaa[1]
		mu2 = lambdaa[2]
		sigma2 = lambdaa[3]
		alpha = lambdaa[4]
	
		prior = 1./norm if min(pop_params['mmin']) <= mmin <= max(pop_params['mmin']) and min(pop_params['mmax']) <= mmax <= max(pop_params['mmax']) and mmin < mmax and max(mmin,min(pop_params['mu1'])) <= mu1 <= min(mmax,max(pop_params['mu1'])) and min(pop_params['sigma1']) <= sigma1 <= max(pop_params['sigma1']) and max(mu1,min(pop_params['mu2'])) <= mu2 <= min(mmax,max(pop_params['mu2'])) and min(pop_params['sigma2']) <= sigma2 <= max(pop_params['sigma2']) and min(pop_params['alpha']) <= alpha <= max(pop_params['alpha']) else 0.
		
	#FIXME: make this a loadable dictionary, like pop models
    
	log_prior = np.log(prior)

	return log_prior

def logposterior(lambdaa, data):

	log_prior = logprior(lambdaa, pop_params, args.popmodel[0])
    
	if not np.isfinite(log_prior):
		return -np.inf

    # (pop prob)(obs likelihood)
	return log_prior + loglikelihood(lambdaa, data)
	
def loglikelihood(lambdaa, data):
    
	log_like = 0.

	for i,likedata in enumerate(data):
	
		pop_prob = pop_probs[i]
		uniform_data = samples_for_select(args.popmodel[i],lambdaa)
    
		n_select = 0.
		like_denom = 0.
		while like_denom <= 0.:
			for m1,m2,dl in uniform_data:
				# (select prob)(pop prob)
				like_denom += select_func(m1,m2,dl)*pop_prob(m1,m2,*lambdaa)
			if like_denom <= 0. or like_denom != like_denom: print('selection function error: {0}'.format(lambdaa))
			n_select += N_SELECT
			uniform_data = samples_for_select(args.popmodel[i],lambdaa)

		like_num = 0.
		for m1,m2 in likedata:
			# (obs likelihood)(pop prob)
			like_num += pop_prob(m1,m2,*lambdaa)

		like_denom = like_denom/N_SELECT    	
		like_num = like_num/len(likedata)
		log_like += np.log(like_num/like_denom)

	return log_like

mmin_ini_tmp = np.random.uniform(min(pop_params['mmin']), max(pop_params['mmin']), N_WALKERS) # initial mmin points
mmax_ini_tmp = np.random.uniform(min(pop_params['mmax']), max(pop_params['mmax']), N_WALKERS) # initial mmax points
mmin_ini = [min(mmin_i,mmax_i) for mmin_i,mmax_i in zip(mmin_ini_tmp,mmax_ini_tmp)]
mmax_ini = [max(mmin_i,mmax_i) for mmin_i,mmax_i in zip(mmin_ini_tmp,mmax_ini_tmp)]

ini = []
if args.popmodel[0] == 'peakcut_m1m2':
	mu_ini = np.random.uniform(min(pop_params['mu']), max(pop_params['mu']), N_WALKERS)
	sigma_ini = np.random.uniform(min(pop_params['sigma']), max(pop_params['sigma']), N_WALKERS)
	ini = ini + [mu_ini,sigma_ini]
elif args.popmodel[0] == 'bimodcut_m1m2':
	mu1_ini_tmp = np.random.uniform(min(pop_params['mu1']), max(pop_params['mu1']), N_WALKERS)
	sigma1_ini = np.random.uniform(min(pop_params['sigma1']), max(pop_params['sigma1']), N_WALKERS)
	mu2_ini_tmp = np.random.uniform(min(pop_params['mu2']), max(pop_params['mu2']), N_WALKERS)
	sigma2_ini = np.random.uniform(min(pop_params['sigma2']), max(pop_params['sigma2']), N_WALKERS)
	alpha_ini = np.random.uniform(min(pop_params['alpha']), max(pop_params['alpha']), N_WALKERS)
	mu1_ini = [min(mu1_i,mu2_i) for mu1_i,mu2_i in zip(mu1_ini_tmp,mu2_ini_tmp)]
	mu2_ini = [max(mu1_i,mu2_i) for mu1_i,mu2_i in zip(mu1_ini_tmp,mu2_ini_tmp)]
	mu1_ini = [mu1 if mmin_ini[j] < mu1 < mmax_ini[j] else np.random.uniform(mmin_ini[j],mmax_ini[j],1)[0] for j,mu1 in enumerate(mu1_ini)]
	mu2_ini = [mu2 if mu1_ini[j] < mu2 < mmax_ini[j] else np.random.uniform(mu1_ini[j],mmax_ini[j],1)[0] for j,mu2 in enumerate(mu2_ini)]
	ini = ini + [mu1_ini,sigma1_ini,mu2_ini,sigma2_ini,alpha_ini]
#FIXME: make loadable dictionary

inisamples = np.array(ini+[mmin_ini,mmax_ini]).T
ndims = inisamples.shape[1] # number of parameters/dimensions
loglikelihood.ncalls = 0 # for bookkeeping set number of likelihood calls to zero
argslist = (likesamps,) # set additional args for the posterior (the data and any variables besides alpha)

sampler = emcee.EnsembleSampler(N_WALKERS, ndims, logposterior, args=argslist) # set up the sampler

# pass the initial samples and total number of samples required
t0 = time() # start time
sampler.run_mcmc(inisamples, N_POSTS+N_BURNIN);
t1 = time()

timeemcee = (t1-t0)
if args.verbose: print("Time taken to run 'emcee' is {} seconds".format(timeemcee))

acls = sampler.get_autocorr_time(quiet=True)
if args.verbose: print("The autocorrelation lengths for population parameters are {0}".format(acls))

# thin out the chain
samples_emcee = sampler.chain[:, N_BURNIN::int(max(acls)), :].reshape((-1, ndims))
if args.verbose: print("Number of independent samples is {0}".format(len(samples_emcee)))

ess = int(len(samples_emcee) / timeemcee)
if args.verbose: print("Effective samples per second: {0}".format(ess))	

# save population parameters posterior
posts = np.ones((len(samples_emcee),1))
pop_param_samps = np.append(np.array(samples_emcee),np.array(posts),axis=1)
col_names = pop.get_pop_params(args.popmodel[0])+',weight' # COLUMN NAMES FOR OUTPUT
np.savetxt(out_path,pop_param_samps[np.isfinite(pop_param_samps).all(axis=1)],header=col_names,comments='',delimiter=',')

