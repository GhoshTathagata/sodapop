#!/usr/bin/env python

'INFER-POP-PARAMS -- infer population parameters based on population model and observations'
__usage__ = 'infer-pop-params pop_params_prior.csv likelihood1.csv likelihood2.csv ... [-p pop_model1 pop_model2 ... -s select_func -o /path/to/output.csv -P target_num_post_samples -w num_walkers -b num_burnin -m num_like_samples -S num_select_samps -v]'
__author__ = 'Philippe Landry (pgjlandry@gmail.com)'
__date__ = '01-2021'

from argparse import ArgumentParser
import numpy as np
import numpy.random
from time import time
import os
import emcee
import sodapop.populations as pop
import sodapop.parameters as prm
import sodapop.priors as pri

parser = ArgumentParser(description=__doc__)
parser.add_argument('popparams')
parser.add_argument('likedata', nargs='+')
parser.add_argument('-c', '--col', help='name of mass1, mass2, distance and likelihood data columns to use, DEFAULT="m1 m2 dL likelihood"', default=['m1','m2','dL','likelihood'], nargs='+')
parser.add_argument('-l', '--nlike', help='number of likelihood samples to use, DEFAULT=5e3', default=5e3)
parser.add_argument('-p', '--popmod', help='name of population model(s), DEFAULT="doublegaussian_m1m2"', default=["doublegaussian_m1m2"], nargs='+')
parser.add_argument('-P', '--priors', help='prior distribution and hyperparameters for each population parameter, DEFAULT="mmin,mmax+flat12,0.,1.,0.,1."', default="mmin,mmax+flat12,0.,1.,0.,1.", nargs='+')
parser.add_argument('-F', '--fixed', help='fixed population parameter values (e.g. mmin,1.0), DEFAULT=False', default=False, nargs='+')
parser.add_argument('-D', '--distprior', help='prior distribution for the distance, DEFAULT="quad,0.,1000."', default="quad,0.,1000.")
parser.add_argument('-B', '--bhpop', help='population parameters for fixed BH mass model, DEFAULT=2. 3. 30.', default=[2.,3.,30.], nargs='+')
parser.add_argument('-f', '--selfunc', help='name of selection function, DEFAULT=False', default=False)
parser.add_argument('-S', '--selpriors', help='ranges in m1,m2 and dL for integrating selection function, DEFAULT="0.5,30.,0.5,30.,0.,1000."', default="0.5,30.,0.5,30.,0.,1000.", nargs='+')
parser.add_argument('-s', '--nsel', help='number of samples to use for integrating selection function, DEFAULT=5000', default=5e3)
parser.add_argument('-t', '--npost', help='target number of posterior samples, DEFAULT=10000', default=1e4)
parser.add_argument('-w', '--nwalk', help='number of MCMC chains, DEFAULT=15', default=15)
parser.add_argument('-b', '--nburn', help='number of burn-in samples, DEFAULT=1000', default=1e3)
parser.add_argument('-o', '--outpath', help='path for output population parameter samples, DEFAULT=AUTO', default=False)
parser.add_argument('-d', '--delim', help='delimiter for data file, DEFAULT=","', default=',')
parser.add_argument('--batch', help='start line of population parameters file for batch mode operation, DEFAULT=False', default=False)
parser.add_argument('-v', '--verbose', action='store_true', default=False)
args = parser.parse_args()

###

if args.outpath: out_path = args.outpath
else: out_path = os.path.dirname(args.likedata[0])+'/'+args.popmod[0]+'.csv'

N_WALKERS = int(args.nwalk)
N_BURNIN = int(args.nburn)
N_POSTS = int(args.npost)
N_SELECT = int(args.nsel)
N_LIKES = int(args.nlike)

if args.verbose: print('walkers: {0}, burn in: {1}, target posterior samples: {2}, likelihood samples: {3}, selection effect samples: {4}'.format(N_WALKERS,N_BURNIN,N_POSTS,N_LIKES,N_SELECT))

lambdabh = args.bhpop

###

# get population model and selection function

pop_probs = [pop.get_pop_prior(args.popmod[i]) for i,likedata in enumerate(args.likedata)]

pop_param_names = (pop.get_pop_params(args.popmod[0])).split(',') # get population parameters from first-specified population model, check that they match what's in the prior sammples later

if not args.selfunc: select_func = lambda *x : 1.
elif args.selfunc == 'False': select_func = lambda *x : 1.
else: select_func = pop.get_select_func(args.selfunc)

dist_shape = (args.distprior).split(',')[0]
dparams = [float(val) for val in (args.distprior).split(',')[1:]]
dfunc = prm.get_param_prior_func(dist_shape)

# store population prior hyperparameters in a dictionary

prior_dict = {}
for prior_str in args.priors:

	prior_key = prior_str.split('+')[0]
	prior_func = prm.get_param_prior_func((prior_str.split('+')[1]).split(',')[0])
	hyp_params = [float(val) for val in (prior_str.split('+')[1]).split(',')[1:]]
	prior_dict[prior_key] = [prior_func,hyp_params]

fixed_dict = {}
fixed_params = []
fixed_vals = []
if args.fixed:
	fixed_params = [fixed_str.split(',')[0] for fixed_str in args.fixed]
	fixed_vals = [fixed_str.split(',')[1] for fixed_str in args.fixed]
	for i,fixed_param in enumerate(fixed_params):
		fixed_dict[fixed_param] = float(fixed_vals[i])
	
lambda_dict = {}
j = 0
for param in pop_param_names:
	if param in fixed_params:
		lambda_dict[param] = lambda x, param=param : fixed_dict[param]
	else:
		lambda_dict[param] = lambda x, j=j : x[j]
		j += 1

# load likelihood samples

if args.verbose: print('Loading likelihood data...')

likesamps = []
for likedata in args.likedata:

	data = np.genfromtxt(likedata,names=True,dtype=None,delimiter=args.delim)
	if args.verbose: print(likedata)
	
	wts = data[args.col[-1]]

	m1s = data[args.col[0]]
	m2s = data[args.col[1]]
	dls = data[args.col[2]]
	ids = np.random.choice(range(len(m1s)),N_LIKES,replace=True,p=wts/np.sum(wts))
	samps = np.array([(m1s[i],m2s[i],dls[i]) for i in ids],dtype='f,f,f')
	
	likesamps.append(samps)

# generate uniform m1,m2 samples and samples for population distance prior for integrating selection function

selectsamps = []
for selectprior in args.selpriors:

	m1lb,m1ub,m2lb,m2ub,dllb,dlub = [float(val) for val in (selectprior).split(',')]
	
	m1_u = np.random.uniform(m1lb,m1ub,N_SELECT)
	m2_u = np.random.uniform(m2lb,m2ub,N_SELECT)
	dl_select = np.random.uniform(dllb,dlub,N_SELECT)
	
	m1_select = []
	m2_select = []
	for m1u,m2u in zip(m1_u,m2_u):
		while m1u < m2u:
			m1u = np.random.uniform(m1lb,m1ub,1)
			m2u = np.random.uniform(m2lb,m2ub,1)
			
		m1_select += [m1u]
		m2_select += [m2u]
	
	samps_select = np.array([(m1_select[j],m2_select[j],dl_select[j]) for j in range(N_SELECT)],dtype='f,f,f')
	
	selectsamps += [samps_select] # uniform m1,m2,dl samples subject to m1 > m2
	
# load population parameter prior

def logprior(lambdaa, lambda_dict, prior_dict):

	prior_keys = prior_dict.keys()
	
	logpriors = []
	for prior_key in prior_keys:
	
		prior_func, hyp_params = prior_dict[prior_key]
		short_lambda = [lambda_dict[param](lambdaa) for param in prior_key.split(',')]
		
		logpriors += [np.log(prior_func(*short_lambda,*hyp_params))]
		
	log_prior = np.sum(logpriors)

	return log_prior

# define population parameter posterior

def logposterior(lambdaa, lambda_dict, data, pop_probs, sdata, sfunc, prior_dict):

	log_prior = logprior(lambdaa, lambda_dict, prior_dict)
	
	if not np.isfinite(log_prior):
#		print('prior:',lambdaa)
		return -np.inf

	# (pop prob)(obs likelihood)
	return log_prior + loglikelihood(lambdaa, lambda_dict, data, pop_probs, sdata, sfunc)
	
def loglikelihood(lambdaa, lambda_dict, data, pop_probs, sdata, sfunc):

	pop_param_names = lambda_dict.keys()
	full_lambda = [lambda_dict[param](lambdaa) for param in pop_param_names]

	log_like = 0.
	for i in range(len(data)):
		likedata = data[i]
		selectdata = sdata[i]
		pop_prob = pop_probs[i]
		
		like_num = 0.
		for m1,m2,dl in likedata:
			# (obs likelihood)(pop prob)
			try: like_num += pop_prob(m1,m2,*full_lambda,*lambdabh)*dfunc(dl,*dparams) # check if the pop model is a NSBH one, and pass it the BH parameters
			except: like_num += pop_prob(m1,m2,*full_lambda)*dfunc(dl,*dparams) # if the pop model is a BNS one, pass it only the NS parameters
		
		if like_num < 0.: print('num:',lambdaa)
		log_like += np.log(like_num)
		
		if not np.isfinite(log_like):
			return -np.inf

	like_denom = 0.
	for m1,m2,dl in selectdata:
		if m1 > lambdabh[-2]:
			pop_prob = pop_probs[-1] # nsbh likelihoods assumed to come last, if present
			like_denom += sfunc(m1,m2,dl)*pop_prob(m1,m2,*full_lambda,*lambdabh)*dfunc(dl,*dparams)
		else:
			pop_prob = pop_probs[0] # bns likelihoods assumed to come first
			like_denom += sfunc(m1,m2,dl)*pop_prob(m1,m2,*full_lambda)*dfunc(dl,*dparams)
	if like_denom <= 0.: print('denom:', lambdaa)
	log_like -= np.log(like_denom)
	
	if not np.isfinite(log_like):
		return -np.inf

	return log_like

# load population parameter prior samples and initialize emcee walkers

pop_params = np.genfromtxt(args.popparams, names=True, dtype=None, delimiter=args.delim, encoding=None)
param_names = list(pop_params.dtype.names)
num_prior_samps = len(pop_params[param_names[0]])
assert(set(param_names) == set(pop_param_names)) 
for param in param_names:
	if param in fixed_params: param_names.remove(param)

if args.batch: ini_idxs = range(int(args.batch),N_WALKERS+int(args.batch))
else: ini_idxs = np.random.choice(range(num_prior_samps),N_WALKERS)
ini_samps = np.array([pop_params[param_name][ini_idxs] for param_name in param_names]).T
ndims = ini_samps.shape[1] # number of pop params

loglikelihood.ncalls = 0 # initialize likelihood call counter
argslist = (lambda_dict,likesamps,pop_probs,selectsamps,select_func,prior_dict) # arguments to pass to posterior besides pop parameters lambdaa

sampler = emcee.EnsembleSampler(N_WALKERS, ndims, logposterior, args=argslist)

# do the mcmc with emcee

t0 = time() # time how long it takes
sampler.run_mcmc(ini_samps, N_POSTS+N_BURNIN);
t1 = time()
timeemcee = (t1-t0)
if args.verbose: print("emcee ran for {} seconds".format(timeemcee))

acls = sampler.get_autocorr_time(quiet=True) # get chain autocorrelation lengths
if args.verbose: print("autocorrelation lengths for population parameters are {0}".format(acls))

if np.all(np.isfinite(acls)):
	samples_emcee = sampler.chain[:, N_BURNIN::int(max(acls)), :].reshape((-1, ndims))
	if args.verbose: print("number of independent samples is {0}".format(len(samples_emcee))) # thin out chain to independent samples only
else:
	if args.verbose: print("error! could not thin chain, raw number of samples is {0}".format(len(sampler.chain[:, N_BURNIN:, :].reshape((-1, ndims)))))
	assert(np.all(np.isfinite(acls)))

ess = int(len(samples_emcee) / timeemcee) # repor effective samples per second
if args.verbose: print("effective samples per second is {0}".format(ess))

# save population parameters posterior

j = 0
samples_out = []
for param in pop_param_names:
	if param in fixed_params: samples_out += [np.full(len(samples_emcee),fixed_dict[param])]
	else:
		samples_out += [samples_emcee[:,j]]
		j += 1

posts = np.ones((len(samples_emcee),1)) # explicitly print equal weights
samples_out += [posts]

post_samps = np.column_stack(samples_out)
col_names = ','.join(pop_param_names)+',weight'
np.savetxt(out_path,post_samps[np.isfinite(post_samps).all(axis=1)],header=col_names,comments='',delimiter=',')

