#!/usr/bin/env python

'INFER-POP-PARAMS -- infer population parameters based on population model and observations'
__usage__ = 'infer-pop-params pop_params_prior.csv likelihood1.csv likelihood2.csv ... [-p pop_model1 pop_model2 ... -s select_func -o /path/to/output.csv -P target_num_post_samples -w num_walkers -b num_burnin -m num_like_samples -S num_select_samps -v]'
__author__ = 'Philippe Landry (pgjlandry@gmail.com)'
__date__ = '01-2021'

from argparse import ArgumentParser
import numpy as np
import numpy.random
from time import time
import os
import emcee
import sodapop.populations as pop
import sodapop.parameters as prm
import sodapop.priors as pri

parser = ArgumentParser(description=__doc__)
parser.add_argument('popparams')
parser.add_argument('likedata', nargs='+')
parser.add_argument('-c', '--col', help='name of mass1, mass2 and likelihood data columns to use, DEFAULT="m1 m2 likelihood"', default=['m1','m2','likelihood'], nargs='+')
parser.add_argument('-l', '--nlike', help='number of likelihood samples to use, DEFAULT=5e3', default=5e3)
parser.add_argument('-p', '--popmod', help='name of population model(s), DEFAULT="doublegaussian_m1m2"', default=["doublegaussian_m1m2"], nargs='+')
parser.add_argument('-P', '--priors', help='prior distribution and hyperparameters for each population parameter, DEFAULT="mmin,mmax+flat12,0.,1.,0.,1."', default="mmin,mmax+flat12,0.,1.,0.,1.", nargs='+')
parser.add_argument('-n', '--npop', help='number of population model realizations, DEFAULT=1e4', default=1e4)
parser.add_argument('-B', '--bhpop', help='population parameters for fixed BH mass model, DEFAULT=2. 3. 30.', default=[2.,3.,30.], nargs='+')
parser.add_argument('-f', '--selfunc', help='name of selection function, DEFAULT=False', default=False)
parser.add_argument('-S', '--selpriors', help='prior distribution in m1,m2 and dL for integrating selection function, plus integration ranges, DEFAULT="flat_m1m2_quad_dL"', default="flat_m1m2_quad_dL,0.5,30.,0.5,30.,0.,1000.", nargs='+')
parser.add_argument('-s', '--nsel', help='number of samples to use for integrating selection function, DEFAULT=5000', default=5e3)
parser.add_argument('-t', '--npost', help='target number of posterior samples, DEFAULT=10000', default=1e4)
parser.add_argument('-w', '--nwalk', help='number of MCMC chains per job, DEFAULT=AUTO', default=False)
parser.add_argument('-b', '--nburn', help='number of burn-in samples, DEFAULT=1000', default=1e3)
parser.add_argument('-o', '--outpath', help='path for output population parameter samples, DEFAULT=AUTO', default=False)
parser.add_argument('-d', '--delim', help='delimiter for data file, DEFAULT=","', default=',')
parser.add_argument('--batch', help='start line of population parameters file for batch mode operation, DEFAULT=False', default=False)
parser.add_argument('-v', '--verbose', action='store_true', default=False)
args = parser.parse_args()

###

if args.outpath: out_path = args.outpath
else: out_path = os.path.dirname(args.likedata[0])+'/'+args.popmodel[0]+'.csv'

N_WALKERS = int(args.numwalkers)
N_BURNIN = int(args.numburnin)
N_POSTS = int(args.postsamps)
N_SELECT = int(args.selectsamps)
N_LIKES = int(args.maxsamps)

if args.verbose: print('walkers: {0}, burn in: {1}, target posterior samples: {2}, likelihood samples: {3}, selection effect samples: {4}'.format(N_WALKERS,N_BURNIN,N_POSTS,N_LIKES,N_SELECT))

N_SELECT_GRID = int(1e4)

lambdabh = args.bhparams

###

# get population model and selection function

pop_probs = [pop.get_pop_prior(args.popmodel[i]) for i,likedata in enumerate(args.likedata)]

pop_param_names = [pop.get_pop_params(args.popmodel[i]) for i,likedata in enumerate(args.likedata)]
pop_param_names_full = list(set(pop_param_names))

if args.select: select_func = pop.get_select_func(args.select)
else: select_func = lambda *x : 1.

# load likelihood samples

if args.verbose: print('Loading likelihood data...')

likesamps = []
for likedata in args.likedata:

	data = np.genfromtxt(likedata,names=True,dtype=None,delimiter=args.delim)
	cols = data.dtype.names
	if args.verbose: print(likedata)
	
	wts = data[args.cols[-1]]

	m1s = data[args.cols[0]]
	m2s = data[args.cols[1]]
	ids = np.random.choice(range(len(m1s)),N_LIKES,replace=True,p=wts/np.sum(wts))
	samps = np.array([(m1s[i],m2s[i]) for i in ids],dtype='f,f')
	
	likesamps.append(samps)

# generate uniform m1,m2 samples and samples for population distance prior for integrating selection function

selectsamps = []
for selectprior in args.selectprior:

	select_prior_func = (selectprior).split(',')[0]
	m1lb,m1ub,m2lb,m2ub,dllb,dlub = [float(val) for val in (selectprior).split(',')[1:]]
	
	m1_select = np.random.uniform(m1lb,m1ub,N_SELECT_GRID)
	m2_select = np.random.uniform(m2lb,m2ub,N_SELECT_GRID)
	dl_select = np.random.uniform(dllb,dlub,N_SELECT_GRID)
	
	select_prior = pri.get_binary_mass_prior(select_prior_func)
	wts_select = [select_prior(m1x,m2x,dlx) for m1x,m2x,dlx in zip(m1_select,m2_select,dl_select)]
	
	idxs_select = np.random.choice(range(N_SELECT_GRID),N_SELECT,True,p=wts_select/np.sum(wts_select))
	samps_select = np.array([(m1_select[j],m2_select[j],dl_select[j]) for j in idxs_select],dtype='f,f,f')
	
selectsamps += [samps_select]
	
# load population parameter prior

def logprior(lambdaa, pop_param_names, priors):

	param_names = []
	prior_funcs = []
	prior_params = []
	for prior_key in priors:

		param_names += [(prior_key.split('+')[0]).split(',')]
		prior_funcs += [(prior_key.split('+')[1]).split(',')[0]]
		prior_params += [[float(val) for val in (prior_key.split('+')[1]).split(',')[1:]]]

	lambdaa_sorted = []
	for param_name in param_names:
		idx = [pop_param_names.index(name) for name in param_name]
		lambdaa_sorted += [lambdaa[idx]]

	logpriors = []
	for param,prior_func,prior_params in zip(lambdaa_sorted,prior_funcs,prior_params):
		prior = prm.get_param_prior_func(prior_func)
		logpriors += [np.log(prior(*param,*prior_params))]
		
	log_prior = np.sum(logpriors)

	return log_prior

# define population parameter posterior

def logposterior(lambdaa, data, pop_probs, sdata, sfunc, pop_param_names, priors):

	log_prior = logprior(lambdaa, pop_param_names, priors)
	
	if not np.isfinite(log_prior):
#		print('prior:',lambdaa)
		return -np.inf

	# (pop prob)(obs likelihood)
	return log_prior + loglikelihood(lambdaa, data, pop_probs, sdata, sfunc)
	
def loglikelihood(lambdaa, data, pop_probs, sdata, sfunc):

	log_like = 0.

	for i,(likedata,selectdata) in enumerate(zip(data,sdata)):
		pop_prob = pop_probs[i]
		
		like_num = 0.
		for m1,m2 in likedata:
			# (obs likelihood)(pop prob)
			try: like_num += pop_prob(m1,m2,*lambdaa,*lambdabh) # check if the pop model is a NSBH one, and pass it the BH parameters
			except: like_num += pop_prob(m1,m2,*lambdaa) # if the pop model is a BNS one, pass it only the NS parameters
			
		like_denom = 0.
		for m1,m2,dl in selectdata:
			# (select prob)(pop prob)
			try: like_denom += sfunc(m1,m2,dl)*pop_prob(m1,m2,*lambdaa,*lambdabh)
			except: like_denom += sfunc(m1,m2,dl)*pop_prob(m1,m2,*lambdaa)
		
		if like_denom <= 0.: print('denom:', lambdaa)
		if like_num < 0.: print('num:',lambdaa)
		like_denom = like_denom/len(selectdata)
		like_num = like_num/len(likedata)
		log_like += np.log(like_num/like_denom)
		
		if not np.isfinite(log_like):
			return -np.inf

	return log_like

# load population parameter prior samples and initialize emcee walkers

pop_params = np.genfromtxt(args.popparams, names=True, dtype=None, delimiter=args.delim, encoding=None)
param_names = pop_params.dtype.names
num_prior_samps = len(pop_params[param_names[0]])

if args.batch: ini_idxs = range(batch,N_WALKERS+batch)
else: ini_idxs = np.random.choice(range(num_prior_samps),N_WALKERS)
ini_samps = np.array([pop_params[param_name][ini_idxs] for param_name in param_names]).T
ndims = ini_samps.shape[1] # number of pop params

loglikelihood.ncalls = 0 # initialize likelihood call counter
argslist = (likesamps,pop_probs,selectsamps,select_func,param_names,args.priors) # arguments to pass to posterior besides pop parameters lambdaa

sampler = emcee.EnsembleSampler(N_WALKERS, ndims, logposterior, args=argslist)

# do the mcmc with emcee

t0 = time() # time how long it takes
sampler.run_mcmc(ini_samps, N_POSTS+N_BURNIN);
t1 = time()
timeemcee = (t1-t0)
if args.verbose: print("emcee ran for {} seconds".format(timeemcee))

acls = sampler.get_autocorr_time(quiet=True) # get chain autocorrelation lengths
if args.verbose: print("autocorrelation lengths for population parameters are {0}".format(acls))

samples_emcee = sampler.chain[:, N_BURNIN::int(max(acls)), :].reshape((-1, ndims))
if args.verbose: print("number of independent samples is {0}".format(len(samples_emcee))) # thin out chain to independent samples only

ess = int(len(samples_emcee) / timeemcee) # repor effective samples per second
if args.verbose: print("effective samples per second is {0}".format(ess))

# save population parameters posterior

posts = np.ones((len(samples_emcee),1)) # explicitly print equal weights
pop_param_samps = np.append(np.array(samples_emcee),np.array(posts),axis=1)
col_names = pop.get_pop_params(args.popmodel[0])+',weight'
np.savetxt(out_path,pop_param_samps[np.isfinite(pop_param_samps).all(axis=1)],header=col_names,comments='',delimiter=',')

